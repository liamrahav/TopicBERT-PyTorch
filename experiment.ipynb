{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbEDDNUuvUm8"
   },
   "source": [
    "### Note:\n",
    "\n",
    "To run in Colab, you will need to add the datasets/ folder to your Google Drive as /data/ (in your Google Drive root directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiJAg_TwZGCn",
    "outputId": "69e5adcb-7c9a-4de8-94bb-0151329a74b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "!pip install transformers\n",
    "import math\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import unittest\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ktPVaPcZGCv"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7Kc9jGtXZGCv"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed, device='cuda'):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "class TwoWayDict(dict):\n",
    "    # From https://stackoverflow.com/questions/1456373/two-way-reverse-map\n",
    "    def __setitem__(self, key, value):\n",
    "        # Remove any previous connections with these values\n",
    "        if key in self:\n",
    "            del self[key]\n",
    "        if value in self:\n",
    "            del self[value]\n",
    "        dict.__setitem__(self, key, value)\n",
    "        dict.__setitem__(self, value, key)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        dict.__delitem__(self, self[key])\n",
    "        dict.__delitem__(self, key)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of connections\"\"\"\n",
    "        return dict.__len__(self) // 2\n",
    "\n",
    "def read_tsv(path):\n",
    "  results = []\n",
    "  with open(path) as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "      results.append(line.split('\\t')) \n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XV-8CAPZGCw"
   },
   "source": [
    "### Reuters8 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0JXcqiFjZM1L",
    "outputId": "a7331aba-75a9-4281-ac9b-93bf24bf8533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlX-s5m8Z6Ct",
    "outputId": "28b7ce06-eada-4e1e-f681-91b35be2b9dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ty_j8dtnxlg"
   },
   "source": [
    "Use a separate `Vocabulary` class that can aggregate vocabularies for whole datassets acrosss train/val/test split. This allows for more accurate word-counting & better integration with NVDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXfq1B7tnw3m",
    "outputId": "26ca6350-c27c-478b-af9d-0f334ec5aa59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4832\n"
     ]
    }
   ],
   "source": [
    "class Vocabulary():\n",
    "  '''Creates a case-insensitive, dictionary-like vocabulary from a raw, \n",
    "  tab-separated dataset.\n",
    "\n",
    "  `Vocabulary` is essentially a wrapper on the builtin `Counter` class. This class\n",
    "  implements __getitem__, which returns the frequency of a given word.\n",
    "\n",
    "  Args:\n",
    "    filenames (:obj:`list` of :obj:`str`): Names of TSV files making up the full\n",
    "      dataset whose vocabulary you want to index. Typically 'train', 'val', and \n",
    "      'test' files.\n",
    "    col_num (:obj:`int`, optional): Set to `1` by default. The column in the TSV\n",
    "      containing raw text. This starts from 0 (e.g. 1 is the 2nd column).\n",
    "    include_stopwords(:obj:`bool`, optional): Set to `False` by default. If `True`,\n",
    "      the vocabulary will include words listed in NLTK's stopwords dataset.\n",
    "    f_min(:obj:`int`, optional): Set to `10` by default. All words with \n",
    "      frequency < f_min are removed from the vocabulary.\n",
    "\n",
    "  '''\n",
    "\n",
    "  def __init__(self, filepaths, col_num=1, include_stopwords=False, f_min=10):\n",
    "    texts = []\n",
    "    for filepath in filepaths:\n",
    "      texts += [x[col_num] for x in read_tsv(filepath)]\n",
    "\n",
    "    words = [word.lower() for text in texts for word in text.split(' ')]\n",
    "\n",
    "    if not include_stopwords:\n",
    "      # remove stopwords, newline\n",
    "      stops = stopwords.words('english')\n",
    "      words = [x for x in words if x not in stops]\n",
    "\n",
    "    c = Counter(words)\n",
    "    self._vocab = Counter({k: c for k, c in c.items() if c >= f_min})\n",
    "\n",
    "  @property \n",
    "  def words(self):\n",
    "    return list(self._vocab.keys())\n",
    "\n",
    "  def __getitem__(self, word):\n",
    "        return self._vocab[word]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.words)\n",
    "\n",
    "f_names = ['training.tsv', 'validation.tsv', 'test.tsv']\n",
    "f_paths = ['/content/drive/My Drive/data/Reuters8/' + x for x in f_names]\n",
    "r8_vocab = Vocabulary(f_paths)\n",
    "print(len(r8_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JBK_aEbqZGCw"
   },
   "outputs": [],
   "source": [
    "class Reuters8Dataset(Dataset):\n",
    "    '''Initializes a PyTorch Dataset with the appropriate Reuters8 data.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): The name of the file containing Ruters8 label/sentence pairs as TSV. This should be \n",
    "            one of 'training', 'test', 'validation'. The files must be located at <cwd>/datasets/Reuters8/\n",
    "        vocab (:obj:`Vocabulary`): A vocabulary object that determines which words are retained by\n",
    "            the dataset when cleaning examples.\n",
    "        label_filepath (:obj:`str`, optional): The label file containing the label ordering, separated by \n",
    "            newlines. By default, this looks to <cwd>/datasets/Reuters8/labels.txt. \n",
    "        one_hot (:obj:`bool`, optional): Set to True by default. Determines if labels are one-hot encoded \n",
    "            vectors (True) or topic strings (False)\n",
    "    '''\n",
    "    REUTERS_URI = '/content/drive/My Drive/data/Reuters8/'\n",
    "    \n",
    "    def _clean_examples(self, examples):\n",
    "        # Switches order of label, sent in dataset. Removes words not in vocab.\n",
    "        cleaned = []\n",
    "        words = self.vocab.words\n",
    "        for ex in examples:\n",
    "            label, sent = ex\n",
    "            new_sent = ' '.join([x.lower() for x in sent.split(' ') if x.lower() in words])\n",
    "            cleaned.append([new_sent, label])\n",
    "            \n",
    "        return cleaned\n",
    "    \n",
    "    def __init__(self, filename, vocab, label_filepath=None, one_hot=True):\n",
    "        self.vocab = vocab\n",
    "        if label_filepath is None:\n",
    "            label_filepath = os.path.join(self.REUTERS_URI, 'labels.txt')\n",
    "            \n",
    "        with open(label_filepath) as f:\n",
    "            self.labels = [x.strip() for x in f.read().strip().split('\\n')]\n",
    "    \n",
    "        self.label_mapping = TwoWayDict()\n",
    "        for i, label in enumerate(self.labels):\n",
    "            self.label_mapping[label] = i\n",
    "            \n",
    "        path = os.path.join(self.REUTERS_URI, filename)\n",
    "        self.examples = self._clean_examples(read_tsv(path))\n",
    "        \n",
    "        if one_hot:\n",
    "            for i, ex in enumerate(self.examples):\n",
    "                _, label = ex\n",
    "                lbl_one_hot = torch.full((len(self.labels),), 0)\n",
    "                lbl_one_hot[self.label_mapping[label]] = 1\n",
    "                self.examples[i][1] =  lbl_one_hot\n",
    "                \n",
    "    @property\n",
    "    def num_labels(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.examples[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "                \n",
    "        \n",
    "r8_train = Reuters8Dataset('training.tsv', r8_vocab)\n",
    "r8_val = Reuters8Dataset('validation.tsv', r8_vocab)\n",
    "r8_test = Reuters8Dataset('test.tsv', r8_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVB66kE9zbst",
    "outputId": "0a30eeb0-4314-4c2e-e923-3a486feb3c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sent/label pair — Ex #107:\n",
      "\t- sent: interco inc th qtr feb net shr cts vs cts net vs sales mln vs mln year shr dlrs vs dlrs net vs sales billion vs billion note results reflect two one stock split july reuter\n",
      "\t- one-hot: tensor([0, 0, 1, 0, 0, 0, 0, 0])\n",
      "\t- int: 2\n",
      "\t- str: earn\n"
     ]
    }
   ],
   "source": [
    "if True: # Set to false to not show example\n",
    "    ex = 107\n",
    "    print('Sample sent/label pair — Ex #{}:'.format(ex))\n",
    "    print('\\t- sent:',r8_train[ex][0].strip()) \n",
    "    print('\\t- one-hot:',r8_train[ex][1]) \n",
    "    # convert one-hot label to int & string\n",
    "    lbl_idx = torch.where(r8_train[ex][1] > 0)[0].item()\n",
    "    print('\\t- int:',lbl_idx) \n",
    "    print('\\t- str:',r8_train.label_mapping[lbl_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EioLwryZGCy",
    "outputId": "5b939b3b-bfe4-412e-c9eb-ec74d7265f58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,  7156,  3001,  4297,  2095, 13292,  3279,  6728,  2121, 14021,\n",
      "         2099,  3279,  2274, 14931,  2015,  5443,  3279, 21469,  2869,  6728,\n",
      "         2121,  5658,  3279,  5443,  3279,  4341, 19875,  2078,  5443, 19875,\n",
      "         2078,  3602,  5658, 23329,  2015,  6409,  8944,  3136, 21469,  2869,\n",
      "         5443, 21469,  2869,  2128, 19901,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n",
      "['[CLS]', 'pioneer', 'systems', 'inc', 'year', 'nov', 'loss', 'op', '##er', 'sh', '##r', 'loss', 'five', 'ct', '##s', 'vs', 'loss', 'dl', '##rs', 'op', '##er', 'net', 'loss', 'vs', 'loss', 'sales', 'ml', '##n', 'vs', 'ml', '##n', 'note', 'net', 'exclude', '##s', 'losses', 'discontinued', 'operations', 'dl', '##rs', 'vs', 'dl', '##rs', 're', '##uter', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[CLS] pioneer systems inc year nov loss oper shr loss five cts vs loss dlrs oper net loss vs loss sales mln vs mln note net excludes losses discontinued operations dlrs vs dlrs reuter [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# We need to provide a custom collate function to DataLoader because we're handling sentences of varying lengths. \n",
    "def collate_fn_bert(batch):\n",
    "  # https://huggingface.co/transformers/preprocessing.html\n",
    "  sents, labels = zip(*batch)\n",
    "  labels = torch.stack([x.long() for x in labels])\n",
    "  encoded = tokenizer(sents, padding=True, max_length=512, truncation=True, return_tensors='pt')\n",
    "  # print([len(x) for x in encoded['input_ids']])\n",
    "  # print(any([len(x) > 512 for x in encoded['input_ids']]))\n",
    "  return encoded['input_ids'], encoded['attention_mask'], labels\n",
    "\n",
    "set_seed(42)\n",
    "dataloader_val = DataLoader(r8_val, batch_size=8, shuffle=False, num_workers=2, collate_fn=collate_fn_bert)\n",
    "\n",
    "if True: # Set to false to not show example\n",
    "    for i, (input_ids, attention_mask, labels) in enumerate(dataloader_val):\n",
    "      if i == 2:\n",
    "        print(input_ids[3])\n",
    "        print(tokenizer.convert_ids_to_tokens(input_ids[3]))\n",
    "        print(tokenizer.decode(input_ids[3]))\n",
    "        print(attention_mask[3])\n",
    "        print(labels[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6gNYwtHLZGCz"
   },
   "outputs": [],
   "source": [
    "def get_init_transformer(transformer):\n",
    "  \"\"\"\n",
    "  Initialization scheme used for transformers:\n",
    "  https://huggingface.co/transformers/_modules/transformers/modeling_bert.html\n",
    "  \"\"\"\n",
    "  def init_transformer(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "        module.weight.data.normal_(mean=0.0, std=transformer.config.initializer_range)\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        module.bias.data.zero_()\n",
    "        module.weight.data.fill_(1.0)\n",
    "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "        module.bias.data.zero_()\n",
    "\n",
    "  return init_transformer\n",
    "\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, num_labels, drop=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = BertModel.from_pretrained('bert-base-uncased')\n",
    "    self.score = nn.Sequential(nn.Dropout(drop), \n",
    "                               nn.Linear(self.encoder.config.hidden_size, num_labels))\n",
    "    self.score.apply(get_init_transformer(self.encoder))  # Important to initialize any additional weights the same way as pretrained encoder. \n",
    "    self.loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels):\n",
    "    hiddens_last = self.encoder(input_ids, attention_mask=attention_mask)[0]  # (batch_size, length, dim), these are last layer embeddings\n",
    "    embs = hiddens_last[:,0,:]  # [CLS] token embeddings\n",
    "    logits = self.score(embs)\n",
    "    # Runs cross-entropy softmax loss on labels\n",
    "    loss_total = self.loss(logits, torch.max(labels, 1)[1])\n",
    "    return logits, loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ug40G42uZGC0"
   },
   "outputs": [],
   "source": [
    "def configure_optimization(model, num_train_steps, num_warmup_steps, lr, weight_decay=0.01):  \n",
    "  # Copied from: https://huggingface.co/transformers/training.html\n",
    "  no_decay = ['bias', 'LayerNorm.weight']\n",
    "  optimizer_grouped_parameters = [{'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], \n",
    "                                   'weight_decay': weight_decay},\n",
    "                                  {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                                   'weight_decay': 0.}]\n",
    "  optimizer = AdamW(optimizer_grouped_parameters, lr=lr)  \n",
    "  scheduler = get_linear_schedule_with_warmup(optimizer, num_training_steps=num_train_steps, num_warmup_steps=num_warmup_steps) \n",
    "  return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1Dz4FfXCZGC0"
   },
   "outputs": [],
   "source": [
    "def get_acc_val(model, device):\n",
    "  num_correct_val = 0\n",
    "  model.eval()  \n",
    "  with torch.no_grad(): \n",
    "    for input_ids, attention_mask, labels in dataloader_val:\n",
    "      input_ids = input_ids.to(device)\n",
    "      attention_mask = attention_mask.to(device)\n",
    "      labels = labels.to(device)\n",
    "      logits, _ = model(input_ids, attention_mask, labels) \n",
    "      preds = torch.max(logits, 1)[1] # get label from max score per example\n",
    "      num_correct_val += (preds == torch.max(labels, 1)[1]).sum()\n",
    "  acc_val = num_correct_val / len(dataloader_val.dataset) * 100.\n",
    "  return acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rHi8oUCrZGC0"
   },
   "outputs": [],
   "source": [
    "def train(model, batch_size=32, num_warmup_steps=10, lr=0.00005, num_epochs=3, clip=1., verbose=True, device='cuda'):\n",
    "  model = model.to(device)  # Move the model to device.  \n",
    "  dataloader_train = DataLoader(r8_train, batch_size=batch_size, shuffle=True, num_workers=2, collate_fn=collate_fn_bert) \n",
    "  num_train_steps = len(r8_train) // batch_size * num_epochs\n",
    "  optimizer, scheduler = configure_optimization(model, num_train_steps, num_warmup_steps, lr)\n",
    "\n",
    "  loss_avg = float('inf')\n",
    "  acc_train = 0.\n",
    "  best_acc_val = 0.\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()  # This turns on the training mode (e.g., enable dropout).\n",
    "    loss_total = 0.\n",
    "    num_correct_train = 0\n",
    "    for batch_ind, (input_ids, attention_mask, labels) in enumerate(dataloader_train):\n",
    "      if (batch_ind + 1) % 200 == 0: \n",
    "        print(batch_ind + 1, '/', len(dataloader_train), 'batches done')\n",
    "      input_ids = input_ids.to(device).long()\n",
    "      attention_mask = attention_mask.to(device)\n",
    "      labels = labels.to(device)      \n",
    "      logits, loss_batch_total = model(input_ids, attention_mask, labels) \n",
    "      preds = torch.max(logits, 1)[1]  # get label from max score per example\n",
    "      num_correct_train += (preds == torch.max(labels, 1)[1]).sum()\n",
    "      loss_total += loss_batch_total.item()            \n",
    "      \n",
    "      loss_batch_avg = loss_batch_total / input_ids.size(0)  \n",
    "      loss_batch_avg.backward()  \n",
    "\n",
    "      if clip > 0.:  # Optional gradient clipping\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "      optimizer.step()  # optimizer updates model weights based on stored gradients\n",
    "      scheduler.step()  # Update lr. \n",
    "      optimizer.zero_grad()  # Reset gradient slots to zero\n",
    "\n",
    "    # Useful training information\n",
    "    loss_avg = loss_total / len(dataloader_train.dataset)\n",
    "    acc_train = num_correct_train / len(dataloader_train.dataset) * 100.\n",
    "\n",
    "    # Check validation performance at the end of every epoch. \n",
    "    acc_val = get_acc_val(model, device)\n",
    "\n",
    "    if verbose:\n",
    "      print('Epoch {:3d} | avg loss {:8.4f} | train acc {:2.2f} | val acc {:2.2f}'.format(epoch + 1, loss_avg, acc_train, acc_val))\n",
    "\n",
    "    if acc_val > best_acc_val: \n",
    "      best_acc_val = acc_val\n",
    "  \n",
    "  if verbose: \n",
    "    print('Final avg loss {:8.4f} | final train acc {:2.2f} | best val acc {:2.2f}'.format(loss_avg, acc_train, best_acc_val))\n",
    "\n",
    "  return best_acc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saoweloiZGC1"
   },
   "source": [
    "## Below Runs BERT on Reuters8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q--M0BweaP-N",
    "outputId": "77d4f958-da8b-427e-a6c6-810a8d7f0eb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipython-autotime\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/c9/b413a24f759641bc27ef98c144b590023c8038dfb8a3f09e713e9dff12c1/ipython_autotime-0.3.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.0.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (54.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.7.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n",
      "Installing collected packages: ipython-autotime\n",
      "Successfully installed ipython-autotime-0.3.1\n",
      "time: 139 µs (started: 2021-04-19 21:26:07 +00:00)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime  # Useful library for tracking runtime on Python Notebooks\n",
    " \n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0j0blsnZZGC1",
    "outputId": "526fd248-1495-4c5e-a334-b30cd1198b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 / 1247 batches done\n",
      "400 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "800 / 1247 batches done\n",
      "1000 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   1 | avg loss   0.0596 | train acc 93.36 | val acc 96.40\n",
      "200 / 1247 batches done\n",
      "400 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "800 / 1247 batches done\n",
      "1000 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   2 | avg loss   0.0180 | train acc 98.48 | val acc 96.60\n",
      "200 / 1247 batches done\n",
      "400 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "800 / 1247 batches done\n",
      "1000 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   3 | avg loss   0.0070 | train acc 99.30 | val acc 97.20\n",
      "Final avg loss   0.0070 | final train acc 99.30 | best val acc 97.20\n",
      "time: 9min 44s (started: 2021-04-18 20:13:09 +00:00)\n"
     ]
    }
   ],
   "source": [
    "if True: # Set True to run. \n",
    "  torch.cuda.empty_cache()\n",
    "  set_seed(42)\n",
    "  model = BertClassifier(r8_train.num_labels)\n",
    "  best_acc_val = train(model, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQpJovGUvu6k"
   },
   "source": [
    "## NVDM\n",
    "\n",
    "Here we implement NVDM as a standalone topic modeler. NVDM is a neural VAE. The goal is to concatenate the output of NVDM's encoder, the posterior distribution $q(\\mathbf{h} | \\mathbf{B})$ with BERT's output (the embedding of the `[CLS]` token), and then fine-tune a joint loss between the two. $\\mathbf{B}$ is the BOW representation of a document $\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyltAZBVr0aT",
    "outputId": "930ff6e1-f8a4-4d15-9ede-b21704b96cdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36.2 s (started: 2021-04-19 21:26:07 +00:00)\n"
     ]
    }
   ],
   "source": [
    "class BOWDataset(Dataset):\n",
    "    '''This class servess as a wrapper for an existing dataset that serves\n",
    "    a BOW repesentation as well as the original. The BOW conversion is done upon\n",
    "    instantiation for efficiency when training.\n",
    "    \n",
    "    Args:\n",
    "      dataset (:obj:`torch.utils.data.Dataset`): The dataset to serve as BOW\n",
    "      vocab (:obj:`Vocabulary`): The vocabulay associated with the dataset.\n",
    "      binary (:obj:`bool`, optional): Whether the BOW should maintain a binary\n",
    "        representation. If `False`, it will contain word frequencies (integers).\n",
    "    '''\n",
    "\n",
    "    def __init__(self, dataset, vocab, binary=False):\n",
    "      self.vocab = vocab\n",
    "      self.examples = []\n",
    "      for sent, label in dataset:\n",
    "        bow = torch.zeros((len(vocab),), dtype=torch.long)\n",
    "        for word in sent.split(' '):\n",
    "          word_index = vocab.words.index(word)\n",
    "          if binary:\n",
    "            bow[word_index] = 1\n",
    "          else:\n",
    "            bow[word_index] += 1\n",
    "\n",
    "        self.examples.append([sent, bow, label])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.examples[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "r8_train_bow = BOWDataset(r8_train, r8_train.vocab)\n",
    "r8_val_bow = BOWDataset(r8_val, r8_val.vocab)\n",
    "r8_test_bow = BOWDataset(r8_test, r8_test.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mT5k82iyJyk",
    "outputId": "25772814-0d7c-49ca-f0f1-9d8b35777d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bell resources boosts stake bhp bell resources ltd said executed underwriting agreement equiticorp ltd acquire mln ordinary shares broken hill pty co ltd mln dlrs bell said statement holds pct bhp billion shares reuter\\n', tensor([1, 0, 0, 0, 0, 0, 0, 0])]\n",
      "['bell resources boosts stake bhp bell resources ltd said executed underwriting agreement equiticorp ltd acquire mln ordinary shares broken hill pty co ltd mln dlrs bell said statement holds pct bhp billion shares reuter\\n', tensor([0, 0, 0,  ..., 0, 0, 0]), tensor([1, 0, 0, 0, 0, 0, 0, 0])]\n",
      "tensor([  4,  15,  19,  23,  30,  51, 119, 273, 377, 388, 396, 397, 398, 399,\n",
      "        400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410])\n",
      "3\n",
      "time: 5.92 ms (started: 2021-04-19 21:26:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(r8_train[10])\n",
    "print(r8_train_bow[10])\n",
    "print(torch.where(r8_train_bow[10][1] > 0)[0])\n",
    "# Frequency of word 'bell' in example\n",
    "print(r8_train_bow[10][1][396].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_ndxZW_zjfr",
    "outputId": "b1764bb1-cd98-4856-c43a-db6ba006f958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.21 s (started: 2021-04-19 21:26:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# We need to provide a custom collate function to DataLoader because we're handling sentences of varying lengths. \n",
    "def collate_fn_topicbert(batch):\n",
    "  # https://huggingface.co/transformers/preprocessing.html\n",
    "  sents, bows, labels = zip(*batch)\n",
    "  labels = torch.stack([x.long() for x in labels])\n",
    "  encoded = tokenizer(sents, padding=True, max_length=512, truncation=True, return_tensors='pt')\n",
    "  return encoded['input_ids'], encoded['attention_mask'], torch.stack(bows).float(), labels\n",
    "\n",
    "dataloader_val_tb = DataLoader(r8_val_bow, batch_size=4, shuffle=False, num_workers=2, collate_fn=collate_fn_topicbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ym4pubUCZawM",
    "outputId": "3903d3a0-8372-434f-eceb-a3153599702b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Token(izer):\n",
      "------------\n",
      "tensor([  101,  6262, 15827,  3477,  5833,  6262, 15827,  2522,  2056,  2604,\n",
      "         5501,  5444, 28324,  7909, 11443, 18376, 15337,  6262, 15827,  2056,\n",
      "         7079, 12174, 11443,  4859,  2028, 14931,  3745,  2691,  4518,  2194,\n",
      "         2056, 24273,  3828, 19875,  2078, 21469,  2869,  2095, 11443,  4859,\n",
      "         8636,  2128, 19901,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0])\n",
      "['[CLS]', 'parker', 'drilling', 'pay', '##out', 'parker', 'drilling', 'co', 'said', 'board', 'directors', 'voted', 'suspend', 'payment', 'divide', '##nds', 'shareholders', 'parker', 'drilling', 'said', 'paying', 'quarterly', 'divide', '##nd', 'one', 'ct', 'share', 'common', 'stock', 'company', 'said', 'expects', 'save', 'ml', '##n', 'dl', '##rs', 'year', 'divide', '##nd', 'suspension', 're', '##uter', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[CLS] parker drilling payout parker drilling co said board directors voted suspend payment dividends shareholders parker drilling said paying quarterly dividend one ct share common stock company said expects save mln dlrs year dividend suspension reuter [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "\n",
      "BOW:\n",
      "------------\n",
      "tensor([   4,   14,   18,   22,   23,   30,   31,   32,   51,   53,   70,   78,\n",
      "          79,  119,  145,  178,  304,  353,  385,  504,  647,  739, 1964, 2020,\n",
      "        2090, 2740, 4214, 4447])\n",
      "['said', 'common', 'shareholders', 'company', 'reuter\\n', 'co', 'board', 'directors', 'dlrs', 'share', 'drilling', 'one', 'year', 'mln', 'stock', 'expects', 'payment', 'dividend', 'payout', 'quarterly', 'ct', 'suspend', 'paying', 'dividends', 'voted', 'suspension', 'save', 'parker']\n",
      "\n",
      "Label:\n",
      "------------\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0])\n",
      "earn\n",
      "time: 150 ms (started: 2021-04-19 21:26:45 +00:00)\n"
     ]
    }
   ],
   "source": [
    "for i, (input_ids, attention_mask, bows, labels) in enumerate(dataloader_val_tb):\n",
    "  if i == 3: # Batch #\n",
    "    print('BERT Token(izer):\\n------------')\n",
    "    print(input_ids[3])\n",
    "    print(tokenizer.convert_ids_to_tokens(input_ids[3]))\n",
    "    print(tokenizer.decode(input_ids[3]))\n",
    "    print(attention_mask[3])\n",
    "    print(bows[3])\n",
    "    print('\\nBOW:\\n------------')\n",
    "    idxs=torch.where(bows[3] > 0)[0]\n",
    "    print(idxs)\n",
    "    print([r8_val_bow.vocab.words[x] for x in idxs])\n",
    "    print('\\nLabel:\\n------------')\n",
    "    print(labels[3])\n",
    "    print(r8_val.label_mapping[torch.where(labels[3] > 0)[0].item()])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Nvz26_T3kGy",
    "outputId": "95b8f431-d7f0-4f2f-9365-e607f3b346af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 45.3 ms (started: 2021-04-19 21:26:45 +00:00)\n"
     ]
    }
   ],
   "source": [
    "class NVDM(nn.Module):\n",
    "  @staticmethod\n",
    "  def _param_initializer(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "      nn.init.xavier_normal_(module.weight)\n",
    "\n",
    "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "      module.bias.data.zero_()\n",
    "\n",
    "  def __init__(self, vocab_size, num_topics=50, hidden_size=256, hidden_layers=1, nonlinearity=nn.Tanh):\n",
    "    super().__init__()\n",
    "    self.num_topics = num_topics\n",
    "    self.vocab_size = vocab_size\n",
    "\n",
    "    # First MLP layer compresses from vocab_size to hidden_size\n",
    "    mlp_layers = [nn.Linear(vocab_size, hidden_size), nonlinearity()]\n",
    "    # Remaining layers operate in dimension hidden_size\n",
    "    for _ in range(hidden_layers - 1):\n",
    "      mlp_layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "      mlp_layers.append(nonlinearity())\n",
    "\n",
    "    self.mlp = nn.Sequential(*mlp_layers)\n",
    "    self.mlp.apply(NVDM._param_initializer)\n",
    "\n",
    "    # Create linear projections for Gaussian params (mean & sigma)\n",
    "    self.mean = nn.Linear(hidden_size, num_topics)\n",
    "    self.mean.apply(NVDM._param_initializer)\n",
    "\n",
    "    # Custom initialization for log_sigma\n",
    "    self.log_sigma = nn.Linear(hidden_size, num_topics)\n",
    "    self.log_sigma.bias.data.zero_()\n",
    "    self.log_sigma.weight.data.fill_(0.)\n",
    "\n",
    "    self.dec_projection = nn.Linear(num_topics, vocab_size)\n",
    "    self.log_softmax = nn.LogSoftmax(-1)\n",
    "\n",
    "  def forward(self, input_bows):\n",
    "    # Run BOW through MLP\n",
    "    pi = self.mlp(input_bows)\n",
    "\n",
    "    # Use this to get mean, log_sig for Gaussian\n",
    "    mean = self.mean(pi)\n",
    "    log_sigma = self.log_sigma(pi)\n",
    "\n",
    "    # Calculate KLD\n",
    "    kld = -0.5 * torch.sum(1 - torch.square(mean) + (2 * log_sigma - torch.exp(2 * log_sigma)), 1)\n",
    "    # kld = mask * kld  # mask paddings\n",
    "\n",
    "    # Use Gaussian reparam. trick to sample from distribution defined by mu, sig\n",
    "    # This provides a sample h_tm from posterior q(h_tm | V) (tm meaning topic model)\n",
    "    epsilons = torch.normal(0, 1, size=(input_bows.size()[0], self.num_topics)).to(input_bows.device)\n",
    "    sample = (torch.exp(log_sigma) * epsilons) + mean\n",
    "\n",
    "    # Softmax to get p(v_i | h_tm), AKA probabilities of words given hidden state\n",
    "    logits = self.log_softmax(self.dec_projection(sample)) \n",
    "\n",
    "    # Lowerbound on NVDM true loss, used for optimization\n",
    "    rec_loss = -1 * torch.sum(logits * input_bows, 1)\n",
    "    loss_nvdm_lb = torch.mean(rec_loss + kld)\n",
    "\n",
    "    return sample, logits, loss_nvdm_lb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDvF1D0CcoMY",
    "outputId": "e16e8650-f34e-4c8b-d67a-dea556b1e820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.2 ms (started: 2021-04-19 21:26:45 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def train_nvdm(model, batch_size=32, lr=0.00005, epochs=1000, verbose=True, device='cuda'):\n",
    "  model = model.to(device)  # Move the model to device.  \n",
    "  dataloader_train = DataLoader(r8_train_bow, batch_size=batch_size, shuffle=True, \n",
    "                                num_workers=2, collate_fn=collate_fn_topicbert)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "  loss_avg = float('inf')\n",
    "  losses = []\n",
    "  for epoch in range(epochs):\n",
    "    model.train()  # This turns on the training mode (e.g., enable dropout).\n",
    "    loss_total = 0.\n",
    "    num_correct_train = 0\n",
    "    for _, _, input_bows, _ in dataloader_train:\n",
    "      input_bows = input_bows.to(device)\n",
    "      _, _, loss_batch_total = model(input_bows) \n",
    "      loss_total += loss_batch_total.item()            \n",
    "      \n",
    "      loss_batch_avg = loss_batch_total / input_bows.size(0)  \n",
    "      loss_batch_avg.backward()  \n",
    "\n",
    "      optimizer.step()  # optimizer updates model weights based on stored gradients\n",
    "      optimizer.zero_grad()  # Reset gradient slots to zero\n",
    "\n",
    "    # Useful training information\n",
    "    loss_avg = loss_total / len(dataloader_train.dataset)\n",
    "    losses.append(loss_avg)\n",
    "\n",
    "    if verbose and (epoch + 1) % 50 == 0:\n",
    "      print('Epoch {:3d} | avg loss {:8.4f} '.format(epoch + 1, loss_avg))\n",
    "  \n",
    "  if verbose: \n",
    "    print('Final avg loss {:8.4f}'.format(loss_avg))\n",
    "    \n",
    "  return loss_avg, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "F-NeoBHw6FxQ",
    "outputId": "96c096a6-0bea-4b6e-c45b-451c7c8e66f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  50 | avg loss 101.5623 \n",
      "Epoch 100 | avg loss  96.5617 \n",
      "Epoch 150 | avg loss  94.0050 \n",
      "Epoch 200 | avg loss  92.1392 \n",
      "Epoch 250 | avg loss  91.1717 \n",
      "Epoch 300 | avg loss  90.5077 \n",
      "Epoch 350 | avg loss  89.9338 \n",
      "Epoch 400 | avg loss  89.6736 \n",
      "Epoch 450 | avg loss  89.3489 \n",
      "Epoch 500 | avg loss  89.0162 \n",
      "Epoch 550 | avg loss  88.8845 \n",
      "Epoch 600 | avg loss  88.6974 \n",
      "Epoch 650 | avg loss  88.7827 \n",
      "Epoch 700 | avg loss  88.3320 \n",
      "Epoch 750 | avg loss  88.2300 \n",
      "Epoch 800 | avg loss  88.1239 \n",
      "Epoch 850 | avg loss  88.0998 \n",
      "Epoch 900 | avg loss  87.9714 \n",
      "Epoch 950 | avg loss  87.8886 \n",
      "Epoch 1000 | avg loss  87.8035 \n",
      "Final avg loss  87.8035\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1h 21min 11s (started: 2021-04-19 00:43:43 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if True: # Set True to run. \n",
    "  torch.cuda.empty_cache()\n",
    "  set_seed(42)\n",
    "  model = NVDM(len(r8_train.vocab))\n",
    "  avg_loss, losses = train_nvdm(model, batch_size=4)\n",
    "\n",
    "  sns.set(style='darkgrid')\n",
    "  plt.plot(np.array(losses))\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Loss\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfZoWQ_fUz68"
   },
   "source": [
    "## TopicBERT\n",
    "\n",
    "Here we merge BERT & NVDM together to yield TopicBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWJ_YGr_U9DZ",
    "outputId": "a3e317ab-ee26-4c18-d117-062a5176c26b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23 ms (started: 2021-04-19 21:26:45 +00:00)\n"
     ]
    }
   ],
   "source": [
    "class TopicBert(nn.Module):\n",
    "  def __init__(self, vocab_size, num_labels, alpha=0.9):\n",
    "    super().__init__()\n",
    "    self.alpha = alpha\n",
    "    self.encoder = BertModel.from_pretrained('bert-base-uncased')\n",
    "    self.nvdm = NVDM(vocab_size)\n",
    "    self.projection = nn.Sequential(\n",
    "      nn.Linear(self.encoder.config.hidden_size + self.nvdm.num_topics, \n",
    "                self.nvdm.num_topics, bias=False), \n",
    "      # nn.GELU() # This is NOT used in paper, but it is used in TF source...\n",
    "      nn.Linear(self.nvdm.num_topics, num_labels)\n",
    "    )\n",
    "    self.projection.apply(get_init_transformer(self.encoder)) \n",
    "\n",
    "    self.bert_loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, bows, labels):\n",
    "    hiddens_last = self.encoder(input_ids, attention_mask=attention_mask)[0]  # (batch_size, length, dim), these are last layer embeddings\n",
    "    embs = hiddens_last[:,0,:]  # [CLS] token embeddings\n",
    "    \n",
    "    h_tm, _, loss_nvdm = self.nvdm(bows)\n",
    "\n",
    "    # combine hidden states & use/optimize jointly\n",
    "    logits = self.projection(torch.cat((embs, h_tm), dim=-1))\n",
    "\n",
    "    # Runs cross-entropy softmax loss on labels\n",
    "    loss_bert = self.bert_loss(logits, torch.max(labels, 1)[1])\n",
    "    loss_total = (self.alpha * loss_bert) + ((1 - self.alpha) * loss_nvdm)\n",
    "    return logits, loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vAgAI0G6Qys",
    "outputId": "0e8631ec-b940-427a-dbf8-c374cf0c9a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.5 ms (started: 2021-04-19 21:43:39 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def get_acc_val(model, device):\n",
    "  num_correct_val = 0\n",
    "  best_f1_val = 0\n",
    "  model.eval()  \n",
    "  all_preds = []\n",
    "  all_labels = []\n",
    "  with torch.no_grad(): \n",
    "    for input_ids, attention_mask, bows, labels in dataloader_val_tb:\n",
    "      input_ids = input_ids.to(device)\n",
    "      attention_mask = attention_mask.to(device)\n",
    "      bows = bows.to(device)\n",
    "      labels = labels.to(device)\n",
    "      logits, _ = model(input_ids, attention_mask, bows, labels) \n",
    "\n",
    "      preds = torch.max(logits, 1)[1] # get label from max score per example\n",
    "      labels = torch.max(labels, 1)[1]\n",
    "      num_correct_val += (preds == labels).sum()\n",
    "\n",
    "      all_preds = np.concatenate((all_preds, preds.cpu().numpy()), axis=None)\n",
    "      all_labels = np.concatenate((all_labels, labels.cpu().numpy()), axis=None)\n",
    "      \n",
    "  acc_val = num_correct_val / len(dataloader_val.dataset) * 100.\n",
    "  return acc_val, f1_score(all_labels, all_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tgGZU0MU6M30",
    "outputId": "4eba984e-e09a-475f-a9ef-909af69c6718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47.9 ms (started: 2021-04-19 21:43:42 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def train_topicbert(model, batch_size=32, num_warmup_steps=10, lr=2e-5, num_epochs=3, clip=1., verbose=True, device='cuda'):\n",
    "  model = model.to(device)  # Move the model to device.  \n",
    "  dataloader_train = DataLoader(r8_train_bow, batch_size=batch_size, shuffle=True, num_workers=2, collate_fn=collate_fn_topicbert) \n",
    "  num_train_steps = len(r8_train_bow) // batch_size * num_epochs\n",
    "  optimizer, scheduler = configure_optimization(model, num_train_steps, num_warmup_steps, lr)\n",
    "\n",
    "  loss_avg = float('inf')\n",
    "  acc_train = 0.\n",
    "  best_acc_val = 0.\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()  # This turns on the training mode (e.g., enable dropout).\n",
    "    loss_total = 0.\n",
    "    num_correct_train = 0\n",
    "    for batch_ind, (input_ids, attention_mask, bows, labels) in enumerate(dataloader_train):\n",
    "      if (batch_ind + 1) % 300 == 0: \n",
    "        print(batch_ind + 1, '/', len(dataloader_train), 'batches done')\n",
    "      input_ids = input_ids.to(device).long()\n",
    "      attention_mask = attention_mask.to(device)\n",
    "      bows = bows.to(device)\n",
    "      labels = labels.to(device)      \n",
    "      logits, loss_batch_total = model(input_ids, attention_mask, bows, labels) \n",
    "      preds = torch.max(logits, 1)[1]  # get label from max score per example\n",
    "      num_correct_train += (preds == torch.max(labels, 1)[1]).sum()\n",
    "      loss_total += loss_batch_total.item()            \n",
    "      \n",
    "      loss_batch_avg = loss_batch_total / input_ids.size(0)  \n",
    "      loss_batch_avg.backward()  \n",
    "\n",
    "      if clip > 0.:  # Optional gradient clipping\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "      optimizer.step()  # optimizer updates model weights based on stored gradients\n",
    "      scheduler.step()  # Update lr. \n",
    "      optimizer.zero_grad()  # Reset gradient slots to zero\n",
    "\n",
    "    # Useful training information\n",
    "    loss_avg = loss_total / len(dataloader_train.dataset)\n",
    "    acc_train = num_correct_train / len(dataloader_train.dataset) * 100.\n",
    "\n",
    "    # Check validation performance at the end of every epoch. \n",
    "    acc_val, best_f1_val = get_acc_val(model, device)\n",
    "\n",
    "    if verbose:\n",
    "      print('Epoch {:3d} | avg loss {:8.4f} | train acc {:2.2f} | val acc {:2.2f} | val best f1 {:.2f}'.format(epoch + 1, loss_avg, acc_train, acc_val, best_f1_val))\n",
    "\n",
    "    if acc_val > best_acc_val: \n",
    "      best_acc_val = acc_val\n",
    "  \n",
    "  if verbose: \n",
    "    print('Final avg loss {:8.4f} | final train acc {:2.2f} | best val acc {:2.2f}'.format(loss_avg, acc_train, best_acc_val))\n",
    "\n",
    "  return best_acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arh9z6G46PkL",
    "outputId": "3f31732b-be05-4945-832f-e6a3e4e5aa30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   1 | avg loss  13.9277 | train acc 89.29 | val acc 96.60 | val best f1 0.91\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   2 | avg loss  13.4076 | train acc 97.73 | val acc 97.20 | val best f1 0.94\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   3 | avg loss  12.9529 | train acc 98.96 | val acc 97.60 | val best f1 0.95\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   4 | avg loss  12.5995 | train acc 98.94 | val acc 96.80 | val best f1 0.93\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   5 | avg loss  12.3379 | train acc 99.22 | val acc 96.80 | val best f1 0.93\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   6 | avg loss  12.1470 | train acc 99.46 | val acc 96.80 | val best f1 0.92\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   7 | avg loss  11.9976 | train acc 99.46 | val acc 97.00 | val best f1 0.93\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   8 | avg loss  11.8930 | train acc 99.60 | val acc 96.40 | val best f1 0.93\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch   9 | avg loss  11.8154 | train acc 99.72 | val acc 97.40 | val best f1 0.95\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch  10 | avg loss  11.7606 | train acc 99.90 | val acc 97.20 | val best f1 0.95\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch  11 | avg loss  11.7011 | train acc 99.90 | val acc 97.20 | val best f1 0.95\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch  12 | avg loss  11.6949 | train acc 99.88 | val acc 97.60 | val best f1 0.95\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch  13 | avg loss  11.6401 | train acc 99.96 | val acc 97.80 | val best f1 0.96\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch  14 | avg loss  11.6202 | train acc 99.96 | val acc 98.00 | val best f1 0.96\n",
      "300 / 1247 batches done\n",
      "600 / 1247 batches done\n",
      "900 / 1247 batches done\n",
      "1200 / 1247 batches done\n",
      "Epoch  15 | avg loss  11.6209 | train acc 99.96 | val acc 98.00 | val best f1 0.96\n",
      "Final avg loss  11.6209 | final train acc 99.96 | best val acc 98.00\n",
      "time: 51min 43s (started: 2021-04-19 21:43:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "if True: # Set True to run. \n",
    "  torch.cuda.empty_cache()\n",
    "  set_seed(42)\n",
    "  model = TopicBert(len(r8_train_bow.vocab), r8_train.num_labels)\n",
    "  best_acc_val = train_topicbert(model, num_epochs=15, batch_size=4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "experiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
